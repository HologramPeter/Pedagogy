{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = {\n",
    "    '+':10000,\n",
    "    '-':20000,\n",
    "    '*':30000,\n",
    "    '/':40000,\n",
    "}\n",
    "\n",
    "symbol_s = {\n",
    "    10000:'+',\n",
    "    20000:'-',\n",
    "    30000:'*',\n",
    "    40000:'/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToArray(s):\n",
    "    a = []\n",
    "    prev_index=0\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in symbol.keys():\n",
    "            a.append(int(s[prev_index:i]))\n",
    "            a.append(symbol[s[i]])\n",
    "            prev_index = i+1\n",
    "            \n",
    "    a.append(int(s[prev_index:len(s)]))\n",
    "    return a\n",
    "    \n",
    "#convert equation to array\n",
    "\n",
    "def convertToString(a):\n",
    "    s=\"\"\n",
    "    for i in a:\n",
    "        if i in symbol_s.keys():\n",
    "            s=s+(symbol_s[i])\n",
    "        else:\n",
    "            s=s+(str(i))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 10000, 2, 40000, 344, 30000, 4]\n",
      "11+2/344*4\n"
     ]
    }
   ],
   "source": [
    "ss = convertToArray(\"11+2/344*4\")\n",
    "print(ss)\n",
    "print(convertToString(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEquation():\n",
    "    eq = []\n",
    "    eq.append(random.randint(lower_bound, upper_bound))\n",
    "    for i in range(4):\n",
    "        eq.append(random.randint(1, 4)*1000)\n",
    "        eq.append(random.randint(lower_bound, upper_bound))\n",
    "    return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730009400042000330008\n"
     ]
    }
   ],
   "source": [
    "test = generateEquation()\n",
    "print(convertToString(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStep(a):  \n",
    "    mark=[[],[]] # step1 and step 2 marks\n",
    "    sol = [a]\n",
    "    \n",
    "    n = len(a)//2\n",
    "    \n",
    "    prev = a\n",
    "    for i in range(n-1,-1,-1):\n",
    "        x = random.randint(0,i)\n",
    "        #print(\"i=\"+str(i)+\"x=\"+str(x))\n",
    "        #print(prev[:2*x],prev[2*x+3:])\n",
    "        \n",
    "        step = prev[:2*x]\n",
    "        \n",
    "        #process step\n",
    "        sym = a[2*x+1]\n",
    "        #print(sym)\n",
    "        error = random.randint(0,4)//4\n",
    "        if sym == 1000:\n",
    "            step.append(prev[2*x] + prev[2*x+2]+error)\n",
    "            mark[0].append(0) if (3000 in prev) or (4000 in prev) else mark[0].append(1)\n",
    "            mark[1].append(0) if error != 0 else mark[1].append(1)\n",
    "        elif sym == 2000:\n",
    "            step.append(prev[2*x] - prev[2*x+2]+error)\n",
    "            mark[0].append(0) if (3000 in prev) or (4000 in prev) else mark[0].append(1)\n",
    "            mark[1].append(0) if error != 0 else mark[1].append(1)\n",
    "        elif sym == 3000:\n",
    "            step.append(prev[2*x] * prev[2*x+2]+error)\n",
    "            mark[0].append(1);\n",
    "            mark[1].append(0) if error != 0 else mark[1].append(1)\n",
    "        elif sym == 4000:\n",
    "            step.append(prev[2*x] / prev[2*x+2]+error)\n",
    "            mark[0].append(1);\n",
    "            mark[1].append(0) if error != 0 else mark[1].append(1)\n",
    "        \n",
    "        step += prev[2*x+3:]\n",
    "        step += [0]*(len(a)-len(step))\n",
    "        #print(step)\n",
    "        sol.append(step)\n",
    "        prev = step\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (sol,mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 2000, 6, 1000, 8, 3000, 10, 2000, 4]\n",
      "[4, 1000, 8, 3000, 10, 2000, 4, 0, 0]\n",
      "[4, 1000, 18, 2000, 4, 0, 0, 0, 0]\n",
      "[4, 1000, 23, 0, 0, 0, 0, 0, 0]\n",
      "[-19, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 1]\n",
      "[1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "test = generateEquation()\n",
    "for step in generateStep(test):\n",
    "    for i in step:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound=10\n",
    "lower_bound=1\n",
    "size = 5000\n",
    "\n",
    "traindata=[]\n",
    "trainlabel1=[]\n",
    "trainlabel2=[]\n",
    "\n",
    "for i in range(size):\n",
    "    try:\n",
    "        (sol, mark) = generateStep(generateEquation())\n",
    "        for j in range(4):\n",
    "            traindata.append(sol[j:j+2])\n",
    "        trainlabel1+=mark[0]\n",
    "        trainlabel2+=mark[1]\n",
    "    except:\n",
    "        i=i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(18, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model1.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "622/622 [==============================] - 0s 483us/step - loss: 34.5285 - accuracy: 0.6938\n",
      "Epoch 2/20\n",
      "622/622 [==============================] - 0s 475us/step - loss: 9.3976 - accuracy: 0.6986\n",
      "Epoch 3/20\n",
      "622/622 [==============================] - 0s 481us/step - loss: 6.3256 - accuracy: 0.7069\n",
      "Epoch 4/20\n",
      "622/622 [==============================] - 0s 475us/step - loss: 5.0104 - accuracy: 0.7147\n",
      "Epoch 5/20\n",
      "622/622 [==============================] - 0s 471us/step - loss: 4.3968 - accuracy: 0.7239\n",
      "Epoch 6/20\n",
      "622/622 [==============================] - 0s 492us/step - loss: 3.7681 - accuracy: 0.7268\n",
      "Epoch 7/20\n",
      "622/622 [==============================] - 0s 476us/step - loss: 3.2996 - accuracy: 0.7295\n",
      "Epoch 8/20\n",
      "622/622 [==============================] - 0s 476us/step - loss: 2.8477 - accuracy: 0.7383\n",
      "Epoch 9/20\n",
      "622/622 [==============================] - 0s 510us/step - loss: 2.6370 - accuracy: 0.7325\n",
      "Epoch 10/20\n",
      "622/622 [==============================] - 0s 478us/step - loss: 2.2823 - accuracy: 0.7380\n",
      "Epoch 11/20\n",
      "622/622 [==============================] - 0s 478us/step - loss: 2.0020 - accuracy: 0.7366\n",
      "Epoch 12/20\n",
      "622/622 [==============================] - 0s 481us/step - loss: 1.9435 - accuracy: 0.7312\n",
      "Epoch 13/20\n",
      "622/622 [==============================] - 0s 471us/step - loss: 1.9796 - accuracy: 0.7385\n",
      "Epoch 14/20\n",
      "622/622 [==============================] - 0s 480us/step - loss: 1.8400 - accuracy: 0.7409\n",
      "Epoch 15/20\n",
      "622/622 [==============================] - 0s 481us/step - loss: 1.5808 - accuracy: 0.7491\n",
      "Epoch 16/20\n",
      "622/622 [==============================] - 0s 476us/step - loss: 1.5885 - accuracy: 0.7402\n",
      "Epoch 17/20\n",
      "622/622 [==============================] - 0s 470us/step - loss: 1.6907 - accuracy: 0.7440\n",
      "Epoch 18/20\n",
      "622/622 [==============================] - 0s 472us/step - loss: 1.5625 - accuracy: 0.7481\n",
      "Epoch 19/20\n",
      "622/622 [==============================] - 0s 474us/step - loss: 1.6092 - accuracy: 0.7402\n",
      "Epoch 20/20\n",
      "622/622 [==============================] - 0s 480us/step - loss: 1.5887 - accuracy: 0.7459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25546c71408>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(traindata, trainlabel1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(18, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model2.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "622/622 [==============================] - 0s 460us/step - loss: 2250.4890 - accuracy: 0.6332\n",
      "Epoch 2/15\n",
      "622/622 [==============================] - 0s 467us/step - loss: 91.4747 - accuracy: 0.6767\n",
      "Epoch 3/15\n",
      "622/622 [==============================] - 0s 467us/step - loss: 37.0919 - accuracy: 0.6815\n",
      "Epoch 4/15\n",
      "622/622 [==============================] - 0s 457us/step - loss: 25.0243 - accuracy: 0.6850\n",
      "Epoch 5/15\n",
      "622/622 [==============================] - 0s 459us/step - loss: 25.2566 - accuracy: 0.6772\n",
      "Epoch 6/15\n",
      "622/622 [==============================] - 0s 470us/step - loss: 24.7202 - accuracy: 0.6783\n",
      "Epoch 7/15\n",
      "622/622 [==============================] - 0s 459us/step - loss: 23.3125 - accuracy: 0.6775\n",
      "Epoch 8/15\n",
      "622/622 [==============================] - 0s 463us/step - loss: 22.2033 - accuracy: 0.6770\n",
      "Epoch 9/15\n",
      "622/622 [==============================] - 0s 460us/step - loss: 21.6818 - accuracy: 0.6817\n",
      "Epoch 10/15\n",
      "622/622 [==============================] - 0s 462us/step - loss: 19.0568 - accuracy: 0.6826\n",
      "Epoch 11/15\n",
      "622/622 [==============================] - 0s 455us/step - loss: 19.1899 - accuracy: 0.6781\n",
      "Epoch 12/15\n",
      "622/622 [==============================] - 0s 462us/step - loss: 19.7635 - accuracy: 0.6791\n",
      "Epoch 13/15\n",
      "622/622 [==============================] - 0s 459us/step - loss: 18.9988 - accuracy: 0.6821\n",
      "Epoch 14/15\n",
      "622/622 [==============================] - 0s 468us/step - loss: 19.5033 - accuracy: 0.6792\n",
      "Epoch 15/15\n",
      "622/622 [==============================] - 0s 459us/step - loss: 20.1062 - accuracy: 0.6805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25553fe50c8>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(traindata, trainlabel2, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 10\n",
    "\n",
    "testdata=[]\n",
    "testlabel1=[]\n",
    "testlabel2=[]\n",
    "\n",
    "for i in range(size):\n",
    "    try:\n",
    "        (sol, mark) = generateStep(generateEquation())\n",
    "        for j in range(4):\n",
    "            testdata.append(sol[j:j+2])\n",
    "        testlabel1+=mark[0]\n",
    "        testlabel2+=mark[1]\n",
    "    except:\n",
    "        i=i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 386us/step - loss: 1.8216 - accuracy: 0.6988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8216372728347778, 0.6988201141357422]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(testdata, testlabel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 382us/step - loss: 24.6680 - accuracy: 0.4755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24.6679744720459, 0.4755396544933319]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(testdata, testlabel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
